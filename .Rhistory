}
}
dev.off()
#####
a<-read.table('/Volumes/My_Passport/Fine-mapping/Trans-ethnic/Data/UKB/rfmix_results/UKB_afr_eur_chr_1_maf_uplifted_sorted_4000_chunk6_phased.anc0.hapcount.txt',
header=T)
ddata<-a[,-c(1:5)]
png('/Users/liam/Dropbox/Prior_info/Multi-ancestry fine-mapping/Model _setting/plots/rfmix_results_6.png',width = 480*4, height = 480*2, units = "px")
#pdf('/Users/liam/Dropbox/Prior_info/Multi-ancestry fine-mapping/Model _setting/plots/rfmix_results.pdf',width = 12, height = 8)
par(mfrow=c(1,4))
for(s in 1:4){
plot(x,col='white',ylim=c(0,201),ylab='UKB individuals',
xlab='SNPs',main='200 individuals LAI')
for(i in 1:200){
x<-ddata[,i+(s-1)*400+1000]
#plot(x)
#j=(i-1)*2+1
j=i
points(x=which(x==0),y=rep(j,length(which(x==0)) ),col=4,cex=0.5)
points(x=which(x==1),y=rep(j,length(which(x==1)) ),col=2,cex=0.5)
points(x=which(x==2),y=rep(j,length(which(x==2)) ),col=3,cex=0.5)
print(i)
}
}
dev.off()
a$POS[1];a$POS[nrow(a)]
new.ld.list<-readRDS('/Volumes/My_Passport/Fine-mapping/Trans-ethnic/Data/UKB/new_cohort_ceu_yri_ld.RDS')
#d=2
d=1
ceu.vcf<-readRDS(paste0('/Volumes/My_Passport/Fine-mapping/Trans-ethnic/Data/UKB/sim1000g_yri_ceu/ceu_chunk',d,'.RDS'))
yri.vcf<-readRDS(paste0('/Volumes/My_Passport/Fine-mapping/Trans-ethnic/Data/UKB/sim1000g_yri_ceu/yri_chunk',d,'.RDS'))
true.x.list<-new.ld.list[[d]]
true.x.list<-list()
true.x.list[[1]]<-matrix(0,dim(new.ld.list[[d]][[1]])[1],dim(new.ld.list[[d]][[1]])[2])
true.x.list[[2]]<-matrix(0,dim(new.ld.list[[d]][[1]])[1],dim(new.ld.list[[d]][[1]])[2])
x<-new.cohort.info[[d]][1,c(1,3)]
new.cohort.info<-readRDS('/Volumes/My_Passport/Fine-mapping/Trans-ethnic/Data/UKB/new_cohort_ceu_yri_info.RDS')
x<-new.cohort.info[[d]][1,c(1,3)]
iden.fun<-function(x){
c(ifelse(is.na(match(x[1],(ceu.vcf$individual_ids))),'YRI','CEU'),
ifelse(is.na(match(x[2],(ceu.vcf$individual_ids))),'YRI','CEU'))
}
a<-apply(new.cohort.info[[d]][,c(1,3)],1,iden.fun)
true.x.list[[1]][which(a[1,]=='YRI'),]<-true.x.list[[1]][which(a[1,]=='YRI'),]+new.ld.list[[d]][[1]][which(a[1,]=='YRI'),]
true.x.list[[1]][which(a[2,]=='YRI'),]<-true.x.list[[1]][which(a[2,]=='YRI'),]+new.ld.list[[d]][[2]][which(a[2,]=='YRI'),]
true.x.list[[2]][which(a[1,]=='CEU'),]<-true.x.list[[2]][which(a[1,]=='CEU'),]+new.ld.list[[d]][[1]][which(a[1,]=='CEU'),]
true.x.list[[2]][which(a[2,]=='CEU'),]<-true.x.list[[2]][which(a[2,]=='CEU'),]+new.ld.list[[d]][[2]][which(a[2,]=='CEU'),]
geno.x.list<-true.x.list[[1]]+true.x.list[[2]]
admix.ld<-cov(geno.x.list)
vali.geno<-cbind(true.x.list[[1]],
true.x.list[[2]])
vali.cov<-cov(vali.geno)
vali.cross.cov<-vali.cov[1:(dim(admix.ld)[1]),(dim(admix.ld)[1]+1):(dim(admix.ld)[1]*2)]
plot(  vali.cross.cov[1,])
plot(  vali.cross.cov[1,])
plot(  vali.cross.cov[1,])
vali.cross.cov[1,]
cbind(vali.cov[1,],)
cbind(vali.cov[1,1:(dim(admix.ld)[1])],vali.cross.cov[1,])
plot(vali.cov[1,1:(dim(admix.ld)[1])],vali.cross.cov[1,])
quantile(vali.cross.cov[1,])
quantile(vali.cov[1,1:(dim(admix.ld)[1])])
quantile(vali.cross.cov[,1])
quantile(vali.cross.cov[,100])
sum(vali.cross.cov>0)
20*50/60
18+16-24
20*50/60
?library()
n=500;p=5
x<-matrix(rnorm(n*p),n,p)
n=500;p=10
x<-matrix(rnorm(n*p),n,p)
beta<-as.matrix(c(rnorm(p/2),rep(0,p/2)))
y<-x%*%beta
y<-x%*%beta+rnorm(n)
lm.r<-lm(y~x)
lm.r<-lm(y~x-1)
sm.r<-summary(lm.r)
sm.r
est.beta<-t(x)%*%solve(x%*%x)%*%y
est.beta<-t(x)%*%solve(t(x)%*%x)%*%y
est.beta<-t(x)%*%solve(t(x)%*%x)%*%t(x)%*%y
est.beta<-(x)%*%solve(t(x)%*%x)%*%t(x)%*%y
est.beta<-solve(t(x)%*%x)%*%t(x)%*%y
t(solve(t(x)%*%x)%*%t(x))%*%solve(t(x)%*%x)%*%t(x)
solve(t(x)%*%x)%*%t(x)%*%t(solve(t(x)%*%x)%*%t(x))
sm.r
y-x[,1]*est.beta[1]
sum((y-x[,1]*est.beta[1])^2)/499
1/sum((y-x[,1]*est.beta[1])^2)
1/(sum((y-x[,1]*est.beta[1])^2)/sqrt(n))
sm.r
sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,1]-mean(x[,1]))^2)
sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,2]-mean(x[,2]))^2)
sqrt(sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,i]-mean(x[,i]))^2))
i=1
sqrt(sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,i]-mean(x[,i]))^2))
i=2
sqrt(sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,i]-mean(x[,i]))^2))
sqrt(sum((y-x%*%est.beta)^2)/(n-1)/sum((x[,i]-mean(x[,i]))^2))
sm.r
sqrt(sum((y-x%*%est.beta)^2)/(n-9)/sum((x[,i]-mean(x[,i]))^2))
sqrt(sum((y-x%*%est.beta)^2)/(n)/sum((x[,i]-mean(x[,i]))^2))
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n)/sum((x[,i]-mean(x[,i]))^2))
i=1
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n)/sum((x[,i]-mean(x[,i]))^2))
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,i]-mean(x[,i]))^2))
i=1
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n-2)/sum((x[,i]-mean(x[,i]))^2))
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n-)/sum((x[,i]-mean(x[,i]))^2))
est.beta[i]/sqrt(sum((y-x%*%est.beta)^2)/(n-1)/sum((x[,i]-mean(x[,i]))^2))
#########Figure 2#######
x<-seq(0.001,1-0.001,0.001)
y<-dbeta(x,0.5,0.5)
plot(x)
plot(x,y)
plot(x,y,type='l')
plot(x,y,type='l',lwd=2,col=2)
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,10))
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4))
segments(0.5,0,0.5,1)
segments(0.5,0,0.5,1,lwd=2,col=3)
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4),xlab=expression(kappa),
ylab='Density',main='Comparison of priors')
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4),xlab=expression(kappa),
ylab='Density',main='Comparison of priors',cex.lab=2)
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4),xlab=expression(kappa),
ylab='Density',main='Comparison of priors',cex.lab=1.5)
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4),xlab=expression(kappa),
ylab='Density',main='Comparison of priors',cex.lab=1.5,cex.axis=2)
plot(x,y,type='l',lwd=2,col=2,ylim=c(0,4),xlab=expression(kappa),
ylab='Density',main='Comparison of priors',cex.lab=1.5,cex.axis=1.5)
segments(0.5,0,0.5,1,lwd=2,col=3)
#####Prior figure ##########
lambda.cauchy<-function(x){
mean(dnorm(x,sd=sqrt.tau))
}
lambda.cauchy<-Vectorize(lambda.cauchy)
x.seq<-seq(-6,6,0.01)
lx.seq<-seq(3,8,0.01)
######Cauchy
tau.sample<-rgamma(1e+5,0.5,0.5)
sqrt.tau<-sqrt(1/tau.sample)
den.seq.cauchy<-lambda.cauchy(x.seq)
den.seq.lcauchy<-lambda.cauchy(lx.seq)
######Hyper-g
tau.sample<-rbeta(1e+5,.5,1)
tau.sample<-tau.sample/(1-tau.sample)
sqrt.tau<-sqrt(1/tau.sample)
den.seq.hyperg<-lambda.cauchy(x.seq)
den.seq.lhyperg<-lambda.cauchy(lx.seq)
######HH
tau.sample<-rbeta(1e+5,.5,.5)
tau.sample<-tau.sample/(1-tau.sample)
sqrt.tau<-sqrt(1/tau.sample)
den.seq.hh<-lambda.cauchy(x.seq)
den.seq.lhh<-lambda.cauchy(lx.seq)
####Normal density
tau=qchisq(0.95,1)/(3000*0.01)
den.seq.normal<-dnorm(x.seq,0,sd=sqrt(1/tau))
den.seq.lnormal<-dnorm(lx.seq,0,sd=sqrt(1/tau))
plot(x.seq,den.seq.hyperg,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density')
points(z.seq,lcz.cauchy,type='l',col=1,lwd=2)
z.seq<-seq(0,8,0.01)
plot(z.seq,lcz.hyper,type='l',col=2,lwd=2,main=bquote(bold('Posterior expectation of '~lambda)),
xlab=bquote(bold('Z')),ylab=bquote(bold('E[')~bold(lambda)~bold('|Z]')),ylim=c(0,8),)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density')
points(x.seq,den.seq.cauchy,type='l',col=1,lwd=2)
points(x.seq,den.seq.hh,type='l',col=4,lwd=2)
legend('topleft',legend=c('Cauchy','Hyper-g','Horseshoe'),col=c(1,2,4),lwd=2,bty='n')
plot(lx.seq,den.seq.lhyperg,type='l',col=2,lwd=2,main='Prior density of effect size (tails)',
xlab=bquote(lambda),ylab='Density',ylim=c(0,0.035))
points(lx.seq,den.seq.lcauchy,type='l',col=1,lwd=2)
points(lx.seq,den.seq.lhh,type='l',col=4,lwd=2)
legend('topright',legend=c('Cauchy','Hyper-g','Horseshoe'),col=c(1,2,4),lwd=2,bty='n')
plot(x.seq,den.seq.hh,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density')
plot(x.seq,den.seq.hh,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,1))
plot(x.seq,den.seq.hh,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
tau
den.seq.normal
points(x.seq,den.seq.normal,type='l',col=1,lwd=2)
points(x.seq,den.seq.lnormal,type='l',col=4,lwd=2)
####Normal density
tau=qchisq(0.95,1)/(3000*0.01)
den.seq.normal<-dnorm(x.seq,0,sd=sqrt(1/tau))
den.seq.lnormal<-dnorm(lx.seq,0,sd=sqrt(1/tau))
den.seq.lnormal
den.normal<-dnorm(x.seq,0,sd=1)
points(x.seq,den.normal,type='l',col=4,lwd=2)
plot(lx.seq,den.seq.lhyperg,type='l',col=2,lwd=2,main='Prior density of effect size (tails)',
xlab=bquote(lambda),ylab='Density',ylim=c(0,0.035))
plot(x.seq,den.seq.hh,type='l',col=2,lwd=2,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col=1,lwd=2)
points(x.seq,den.normal,type='l',col=4,lwd=2)
points(x.seq,den.seq.normal,type='l',col=5,lwd=2)
points(x.seq,den.seq.normal,type='l',col=3,lwd=2)
points(x.seq,den.seq.normal,type='l',col=6,lwd=2)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col=6,lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
points(x.seq,den.seq.normal,type='l',col='yellow',lwd=3)
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard Normal'),col=c(2,'cyan',4),lwd=3,bty='n')
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
unit.x.seq<-c(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
unit.x.seq
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
tau
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
legend(0.2,3,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
legend(0.2,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
pdf('/Users/liam/Documents/Grant/K99/code_plot/lambda_prior.pdf',
heigh=6,width = 12)
par(mfrow=c(1,2))
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend(0.1,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=2)
dev.off()
pdf('/Users/liam/Documents/Grant/K99/code_plot/lambda_prior.pdf',
heigh=12,width = 6)
par(mfrow=c(1,2))
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend(0.1,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
dev.off()
pdf('/Users/liam/Documents/Grant/K99/code_plot/lambda_prior.pdf',
heigh=12,width = 6)
par(mfrow=c(2,1))
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend(0.1,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
dev.off()
pdf('/Users/liam/Documents/Grant/K99/code_plot/lambda_prior.pdf',
heigh=8,width = 6)
par(mfrow=c(2,1))
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend(0.1,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size (origin)'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
dev.off()
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of '~kappa),
xlab=bquote(lambda),ylab='Density',ylim=c(0,4))
pdf('/Users/liam/Documents/Grant/K99/code_plot/lambda_prior.pdf',
heigh=8,width = 6)
par(mfrow=c(2,1))
unit.x.seq<-seq(0.001,1-0.001,0.001)
plot(unit.x.seq,dbeta(unit.x.seq,0.5,0.5),type='l',col=2,lwd=3,main=bquote('Prior density of '~kappa),
xlab=bquote(kappa),ylab='Density',ylim=c(0,4))
segments(0.5,0,0.5,1,col='cyan',lwd=3)
segments(tau/(1+tau),0,tau/(1+tau),1,col=4,lwd=3)
legend(0.1,4,legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
plot(x.seq,den.seq.hh,type='l',col=2,lwd=3,main=bquote('Prior density of effect size'),
xlab=bquote(lambda),ylab='Density',ylim=c(0,.4))
points(x.seq,den.seq.normal,type='l',col='cyan',lwd=3)
points(x.seq,den.normal,type='l',col=4,lwd=3)
#legend('topleft',legend=c('Horseshoe','Normal adjusted by heri.','Standard normal'),
#     col=c(2,'cyan',4),lwd=3,bty='n',cex=1)
dev.off()
?model.matrix
# #devtools::install_github("klutometis/roxygen")
# rm(list=ls())
#  install.packages('Rcpp')
# install.packages('RcppArmadillo')
# install.packages('RcppGSL')
# install.packages('roxygen2')
# install.packages('glmnet')
# install.packages('dplyr')
#
# library("devtools")
library(roxygen2)
library(Rcpp)
#install.packages("pkgKitten")
library(RcppArmadillo)
library(glmnet)
library(tools)
library(RcppGSL)
library(Matrix)
setwd('/Users/liam/Dropbox/Prior_info/FINEMAPPING/Package/')
#RcppArmadillo.package.skeleton("test")
#setwd('/Users/zikunyang/Documents/GitHub/CARMA')
#setwd('/Users/zikunyang/Dropbox/Prior_info/FINEMAPPING/Package/CARMA')
setwd('/Users/liam/Documents/Meeting_Prof.Iuliana/Fine-mapping/Coding/package/CARMA')
#setwd('/Users/zikunyang/Documents/GitHub/CARMA')
document()
# install.packages("devtools")
# #devtools::install_github("klutometis/roxygen")
# rm(list=ls())
#  install.packages('Rcpp')
# install.packages('RcppArmadillo')
# install.packages('RcppGSL')
# install.packages('roxygen2')
# install.packages('glmnet')
# install.packages('dplyr')
#
library("devtools")
install.packages('/Users/liam/Documents/GitHub/CARMA_1.0.tar.gz', repos = NULL, type="source")
install.packages('/Users/liam/Documents/GitHub/CARMA_1.0.tar.gz', repos = NULL, type="source")
library(CARMA)
setwd('/Users/zikunyang/Documents/GitHub/CARMA')
#setwd('/Users/zikunyang/Documents/GitHub/CARMA')
document()
build()
setwd('/Users/zikunyang/Documents/GitHub/CARMA')
setwd('/Users/liam/Documents/GitHub/CARMA')
build()
install.packages('/Users/liam/Documents/GitHub/CARMA_1.0.tar.gz', repos = NULL, type="source")
knitr::opts_chunk$set(echo = TRUE)
##### setting up the working directory or the wd where the data are stored
setwd('CARMA')
getwd()
setwd('/Users/liam')
##### setting up the working directory or the wd where the data are stored
setwd('CARMA')
setwd('/Users/liam')
getwd("")
getwd()
##### setting up the working directory or the wd where the data are stored
setwd('/Users/liam')
setwd('CARMA')
##### setting up the working directory or the wd where the data are stored
setwd('CARMA')
knitr::opts_chunk$set(echo = TRUE)
##### setting up the working directory or the wd where the data are stored
setwd('CARMA')
###### load the GWAS summary statistics
sumstat<- fread(file = "Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
library(data.table)
library(magrittr)
library(dplyr)
library(devtools)
library(R.utils)
pkgs = c("data.table", "magrittr", "dplyr", "devtools","R.utlis")
pkgs.na = pkgs[!pkgs %in% installed.packages()[, "Package"]]
if (length(pkgs.na) > 0) {
install.packages(pkgs.na)
}
if (!"CARMA" %in% installed.packages()[, "Package"]) {
devtools::install_github("ZikunY/CARMA")
}
###### load the GWAS summary statistics
sumstat<- fread(file = "Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
install.packages("R.utlis")
install.packages("R.utils")
library(R.utils)
###### load the GWAS summary statistics
sumstat<- fread(file = "Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
###### load the pair-wise LD matrix (assuming the variants are sorted in the same order
###### as the variants in sumstat file)
ld =  fread(file = "Sample_data/sumstats_chr1_200937832_201937832_ld.txt.gz",
sep = "\t", header = F, check.names = F, data.table = F,
stringsAsFactors = F)
###### load the pair-wise LD matrix (assuming the variants are sorted in the same order
###### as the variants in sumstat file)
ld =  fread(file = "Sample_data/sumstats_chr1_200937832_201937832_ld.txt.gz",
sep = "\t", header = F, check.names = F, data.table = F,
stringsAsFactors = F)
print(head(sumstat))
library(data.table)
options(digits=2)
sumstat<- fread(file = "/Users/liam/CARMA/Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
print(head(sumstat))
library(data.table)
options(digits=2)
sumstat<- fread(file = "/Users/liam/CARMA/Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
print(head(sumstat))
print(head(sumstat))
```
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-sumstat$Z
ld.list[[1]]<-as.matrix(ld)
lambda.list[[1]]<-1
CARMA.results<-CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=F)
library(CARMA)
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-sumstat$Z
ld.list[[1]]<-as.matrix(ld)
lambda.list[[1]]<-1
CARMA.results<-CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=F)
library(CARMA)
CARMA.results<-CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=F)
detach("package:CARMA", unload = TRUE)
library(CARMA)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(magrittr)
library(dplyr)
library(devtools)
library(R.utils)
library(CARMA)
###### load the GWAS summary statistics
sumstat<- fread(file = "Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
###### load the pair-wise LD matrix (assuming the variants are sorted in the same order
###### as the variants in sumstat file)
ld =  fread(file = "Sample_data/sumstats_chr1_200937832_201937832_ld.txt.gz",
sep = "\t", header = F, check.names = F, data.table = F,
stringsAsFactors = F)
library(data.table)
options(digits=2)
sumstat<- fread(file = "/Users/liam/CARMA/Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-sumstat$Z
ld.list[[1]]<-as.matrix(ld)
lambda.list[[1]]<-1
CARMA.results<-CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=F)
###### Posterior inclusion probability (PIP) and credible set (CS)
sumstat.result = sumstat %>% mutate(PIP = CARMA.results[[1]]$PIPs, CS = 0)
if(length(CARMA.results[[1]]$`Credible set`[[2]])!=0){
for(l in 1:length(CARMA.results[[1]]$`Credible set`[[2]])){
sumstat.result$CS[CARMA.results[[1]]$`Credible set`[[2]][[l]]]=l
}
}
###### write the GWAS summary statistics with PIP and CS
fwrite(x = sumstat.result,
file = "Sample_data/sumstats_chr1_200937832_201937832_carma.txt.gz",
sep = "\t", quote = F, na = "NA", row.names = F, col.names = T,
compress = "gzip")
h=1
ref.table<-read.csv('/Volumes/My_Passport/1000Genome/new_2022/table1.csv')
Z<-read.table(paste0('/Volumes/My_Passport/Fine-mapping/[Vignettes]/data/',ref.table$chr[h],'_',(ref.table$region_start [h]),
'_',ref.table$region_end[h]),header=T)
c1<-CARMA.results
CARMA.results<-CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=F)
plot(c1[[1]]$PIPs)
c2<-CARMA.results
plot(c2[[1]]$PIPs)
?CARMA_fixed_sigma
setwd('/Users/liam/Documents/GitHub/CARMA')
build()
install.packages('/Users/liam/Documents/GitHub/CARMA_1.0.tar.gz', repos = NULL, type="source")
